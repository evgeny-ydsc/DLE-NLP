{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZdznZNyZ36t5"
      },
      "source": [
        "# Проект Автодополнение текстов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMYC9T6i36t_"
      },
      "source": [
        "Вы работаете в соцсетевом приложении, где пользователи постят короткие тексты. В продукте стоит задача — добавить возможность автодополнения текстов. Разработчики просят вас создать модель, которую можно запускать на мобильных устройствах. Для смартфонов есть значительные требования по оперативной памяти и скорости работы, так что важна легковесность модели."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "onS-SYto36uA"
      },
      "source": [
        "## Постановка задачи\n",
        "**Создать нейросеть, которая на основе начала фразы предсказывает её продолжение**.\n",
        "\n",
        "Поэтапное описание задачи:\n",
        "1. Взять датасет от разработчиков, очистить его, подготовить для обучения модели.\n",
        "1. Реализовать и обучить модель на основе рекуррентных нейронных сетей.\n",
        "1. Замерить качество разработанной и обученной модели.\n",
        "1. Взять более «тяжёлую» предобученную модель из Transformers и замерить её качество.\n",
        "1. Проанализировать результаты и **дать рекомендации** разработчикам: стоит ли **использовать лёгкую модель или** лучше постараться поработать с ограничениями по памяти и **использовать большую предобученную**.\n",
        "\n",
        "## Критерии успеха\n",
        "- Используемые метрики качества: ROUGE-1 и ROUGE-2\n",
        "- Минимальных порогов качества модели в задаче не задано\n",
        "\n",
        "\n",
        "## Описание данных\n",
        "\n",
        "датасет с короткими постами sentiment140\n",
        "\n",
        "https://code.s3.yandex.net/deep-learning/tweets.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N_xJyxMe36uC"
      },
      "source": [
        "# Этап 0. Подготовка окружения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58t6n_5C36uC"
      },
      "source": [
        "В задании требовалось весь код убрать в директории. Код доступен тут:\n",
        "\n",
        "https://github.com/evgeny-ydsc/DLE-NLP"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "VuLHkYrA36uD"
      },
      "outputs": [],
      "source": [
        "#!pip install -r requirements_sprint_2_project.txt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate\n",
        "!pip install rouge_score"
      ],
      "metadata": {
        "id": "HSgu8AM958A8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "143a3fc0-a4f2-40b8-e348-c5c261d2fa33"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.12/dist-packages (0.4.5)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.0.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.0.2)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (2.32.4)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.12/dist-packages (from evaluate) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2025.3.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from evaluate) (0.34.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from evaluate) (25.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (3.19.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (18.1.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (3.12.15)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.15.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub>=0.7.0->evaluate) (1.1.8)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.19.0->evaluate) (2025.8.3)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->evaluate) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.7.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (6.6.4)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (0.3.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2021.05.0->evaluate) (1.20.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Requirement already satisfied: rouge_score in /usr/local/lib/python3.12/dist-packages (0.1.2)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from rouge_score) (3.9.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from rouge_score) (2.0.2)\n",
            "Requirement already satisfied: six>=1.14.0 in /usr/local/lib/python3.12/dist-packages (from rouge_score) (1.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from nltk->rouge_score) (4.67.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "md6SG0Kl6lqc",
        "outputId": "f033d9d4-de37-49af-9725-b6b2b5789858"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "q9mYYBcv36uF"
      },
      "outputs": [],
      "source": [
        "import evaluate\n",
        "from drive.MyDrive.project1.src.data_utils import download_dataset\n",
        "from drive.MyDrive.project1.src.next_token_dataset import prepare_loaders\n",
        "from drive.MyDrive.project1.src.lstm_model import LSTMGenerator\n",
        "from drive.MyDrive.project1.src.lstm_train_eval import ModelTrainer\n",
        "from drive.MyDrive.project1.src.eval_transformer_pipeline import Distilgpt2Generator"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W6oGdnoF36uF"
      },
      "source": [
        "# Этап 1. Сбор и подготовка данных"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4Cx5rNG36uG"
      },
      "source": [
        "👷🚧🚧🚧🚧🚧 перед загрузкой на GPU заменить 200 на 20000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nLAhrBpA36uG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9b66c4b-5427-471c-d243-00a3c05d80c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "raw_data_path = \"drive/MyDrive/project1/data/tweets.txt\"\n",
        "download_dataset(\"https://code.s3.yandex.net/deep-learning/tweets.txt\",\n",
        "                                 raw_data_path)\n",
        "train_loader, val_loader, test_loader, tokenizer, val_texts, test_texts = \\\n",
        "    prepare_loaders (raw_data_path, batch_size=256, max_texts_count=10_000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0ZsE690936uH"
      },
      "source": [
        "# Этап 2. Реализация рекуррентной сети\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "X6tt04Vq36uH"
      },
      "outputs": [],
      "source": [
        "model = LSTMGenerator(tokenizer.vocab_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36Rr_B8I36uH"
      },
      "source": [
        "# Этап 3. Тренировка модели"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "w7D56alcNuag"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "hWXb38sr36uH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f37b6929-d5bc-470f-9cfd-87a910768930"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 371/371 [01:29<00:00,  4.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Train Loss: 7.174 | Val Loss: 6.660 | Val Accuracy: 9.21%| rouge1: 0.002 | rouge2: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 371/371 [01:27<00:00,  4.24it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2 | Train Loss: 6.210 | Val Loss: 6.375 | Val Accuracy: 10.55%| rouge1: 0.002 | rouge2: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 371/371 [01:29<00:00,  4.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3 | Train Loss: 5.717 | Val Loss: 6.276 | Val Accuracy: 12.33%| rouge1: 0.005 | rouge2: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 371/371 [01:29<00:00,  4.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4 | Train Loss: 5.288 | Val Loss: 6.271 | Val Accuracy: 13.17%| rouge1: 0.009 | rouge2: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 371/371 [01:27<00:00,  4.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5 | Train Loss: 4.886 | Val Loss: 6.321 | Val Accuracy: 13.30%| rouge1: 0.011 | rouge2: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 371/371 [01:30<00:00,  4.11it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6 | Train Loss: 4.503 | Val Loss: 6.392 | Val Accuracy: 13.58%| rouge1: 0.010 | rouge2: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 371/371 [01:29<00:00,  4.15it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7 | Train Loss: 4.144 | Val Loss: 6.506 | Val Accuracy: 13.53%| rouge1: 0.009 | rouge2: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 371/371 [01:29<00:00,  4.16it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8 | Train Loss: 3.814 | Val Loss: 6.625 | Val Accuracy: 13.36%| rouge1: 0.007 | rouge2: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 371/371 [01:29<00:00,  4.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9 | Train Loss: 3.517 | Val Loss: 6.757 | Val Accuracy: 13.10%| rouge1: 0.007 | rouge2: 0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 371/371 [01:29<00:00,  4.14it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10 | Train Loss: 3.248 | Val Loss: 6.899 | Val Accuracy: 12.86%| rouge1: 0.008 | rouge2: 0.000\n"
          ]
        }
      ],
      "source": [
        "trainer = ModelTrainer (model, tokenizer)\n",
        "trainer.train(train_loader, val_loader, val_texts, n_epochs=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Видно, что начиная с 5й эпохи модель начала переобучатсья. Но GPU Практикума недоступна, а ресурс colab тоже уже закончился и не гарантирован (уже обрывался по полпути ранее). Поэтому не рискую его перезапускать ещё раз, оставлю модель как есть в этот раз."
      ],
      "metadata": {
        "id": "jj7aKCFZZ44u"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "54_yjEAH36uJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a42c0d7-a718-4909-f25c-8caf064ca393"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------\n",
            "оригинальная строка: locked out of my outlook account for the 3rd time in 3 days\n",
            "оригинальное начало: locked out of my outlook account for the 3rd\n",
            "оригинальный конец :  time in 3 days\n",
            "предсказанный конец: ineverandiandiam##icansoundsandfor##k##gfor\n",
            "rouge1=0.000, rouge2=0.000\n",
            "\n",
            "----------------------------------------------\n",
            "оригинальная строка: back at the office still only 3 days until another long weekend\n",
            "оригинальное начало: back at the office still only 3 days until anot\n",
            "оригинальный конец : her long weekend\n",
            "предсказанный конец: ofofand##es##pformeiandiandstillandineedme\n",
            "rouge1=0.000, rouge2=0.000\n",
            "\n",
            "----------------------------------------------\n",
            "оригинальная строка: beachbassbone roomie was home all day all he had to do was scratch at the door comforter has to goto large laundromat machines\n",
            "оригинальное начало: beachbassbone roomie was home all day all he had to do was scratch at the door comforter has t\n",
            "оригинальный конец : o goto large laundromat machines\n",
            "предсказанный конец: ##wee##e##g##d##n##d##n##d##n##d##n##d##n##d##n##d##n##d##n##d##n##d##n##d##n##d##n##d##n##d##n##d\n",
            "rouge1=0.000, rouge2=0.000\n",
            "\n"
          ]
        }
      ],
      "source": [
        "rouge = evaluate.load(\"rouge\")\n",
        "for line in test_texts[:3]:\n",
        "    l = len(line)\n",
        "    i = int(l*0.75)\n",
        "    start = line [:i]\n",
        "    finish = line [i:]\n",
        "    predicted_finish = model.generate_output_text(tokenizer, start, l-i)\n",
        "    results = rouge.compute(predictions=[predicted_finish], references=[finish])\n",
        "    print (f\"----------------------------------------------\")\n",
        "    print (f\"оригинальная строка: {line}\")\n",
        "    print (f\"оригинальное начало: {start}\")\n",
        "    print (f\"оригинальный конец : {finish}\")\n",
        "    print (f\"предсказанный конец: {predicted_finish}\")\n",
        "    print (f\"rouge1={results['rouge1']:.3f}, rouge2={results['rouge2']:.3f}\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rn47i2BG36uK"
      },
      "source": [
        "# Этап 4. Использование предобученного трансформера"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "LjDWuQ_W36uK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "089ae232-49d9-4011-92ca-21c6b3b1dcd5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ],
      "source": [
        "bert_model = Distilgpt2Generator()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "mLLhtrSx36uK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4537118d-ea16-484e-e781-731c1690a54c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=15) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=16) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------\n",
            "оригинальная строка: locked out of my outlook account for the 3rd time in 3 days\n",
            "оригинальное начало: locked out of my outlook account for the 3rd\n",
            "оригинальный конец :  time in 3 days\n",
            "предсказанный конец:  I can handle that, but I’d like to go back and think about my experience in the game.\n",
            "\n",
            "\n",
            "I like what I see in The Legend of Zelda: Breath of the Wild. Some of the things that I liked about this game are all that are going to make me appreciate it more than any other game that I've played. It’s an old-school Zelda game that I loved, and it’s a lot better than that.\n",
            "The Legend of Zelda: Breath of the Wild is the most beautiful, thrilling Zelda game I played, and I like what it is. I’ll continue to enjoy playing, and I’ll get to experience it.\n",
            "As for the story, I really enjoy the story. I can’t wait to see what you guys think.\n",
            "The Legend of Zelda: Breath of the Wild is my favorite Zelda game I’ve seen.\n",
            "You can check out the rest of the video in my archive.\n",
            "If you liked this post, follow me on Twitter and like me on Youtube.\n",
            "rouge1=0.011, rouge2=0.000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Both `max_new_tokens` (=256) and `max_length`(=32) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------\n",
            "оригинальная строка: back at the office still only 3 days until another long weekend\n",
            "оригинальное начало: back at the office still only 3 days until anot\n",
            "оригинальный конец : her long weekend\n",
            "предсказанный конец: d a new one on the table. In the same office, I had a new one on the table. In the same office, I had a new one on the table. In the same office, I had a new one on the table. In the same office, I had a new one on the table. In the same office, I had a new one on the table. In the same office, and in the same office, I had a new one on the table. In the same office, and in the same office, I was the only one left. I was the only one left.\n",
            "The first time I was at the office, I had a new one on the table. In the same office, and in the same office, I was the only one left. I was the only one left. I was the only one left. I was the only one left. I was the only one left. I was the only one left.\n",
            "I was the only one left.\n",
            "I was the only one left.\n",
            "The next time I was at the office, I had a new one on the table. In the same office, I had a\n",
            "rouge1=0.000, rouge2=0.000\n",
            "----------------------------------------------\n",
            "оригинальная строка: beachbassbone roomie was home all day all he had to do was scratch at the door comforter has to goto large laundromat machines\n",
            "оригинальное начало: beachbassbone roomie was home all day all he had to do was scratch at the door comforter has t\n",
            "оригинальный конец : o goto large laundromat machines\n",
            "предсказанный конец: \n",
            "rouge1=0.000, rouge2=0.000\n"
          ]
        }
      ],
      "source": [
        "for line in test_texts[:3]:\n",
        "    l = len(line)\n",
        "    i = int(l*0.75)\n",
        "    start = line [:i]\n",
        "    finish = line [i:]\n",
        "    predicted_finish = bert_model.generate_output_text(start, l-i)[l:]\n",
        "    results = rouge.compute(predictions=[predicted_finish], references=[finish])\n",
        "    print (f\"----------------------------------------------\")\n",
        "    print (f\"оригинальная строка: {line}\")\n",
        "    print (f\"оригинальное начало: {start}\")\n",
        "    print (f\"оригинальный конец : {finish}\")\n",
        "    print (f\"предсказанный конец: {predicted_finish}\")\n",
        "    print (f\"rouge1={results['rouge1']:.3f}, rouge2={results['rouge2']:.3f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6XVXq5g336uL"
      },
      "source": [
        "# Этап 5. Формулирование выводов"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1-1nptU36uL"
      },
      "source": [
        "\n",
        "- В соответствии с поставленной задачей(см. первый раздел)\n",
        "    - была проведена подготовка данных и их разведочный анализ, в результате которых:\n",
        "        - были исправлены имена полей, исправлены типы данных, удалены малополезные признаки (в т. ч. с учётом мультиколлинеарности), заполнены пропуски, удалены явные и неявные дубликаты, ...\n",
        "    - была натренирована модель, предсказывающая ...\n",
        "        - выбрана наиболее оптимальная модель - **...**, показавшая наилучшие результаты:\n",
        "            - качество предсказания: ...\n",
        "            - это удовлетворяет заданный критерий качества: ..."
      ]
    }
  ],
  "metadata": {
    "ExecuteTimeLog": [
      {
        "duration": 45,
        "start_time": "2025-04-13T00:31:37.601Z"
      },
      {
        "duration": 6,
        "start_time": "2025-04-13T00:35:12.169Z"
      },
      {
        "duration": 3185,
        "start_time": "2025-04-16T20:05:37.378Z"
      },
      {
        "duration": 7396,
        "start_time": "2025-04-16T20:06:11.392Z"
      },
      {
        "duration": 1458,
        "start_time": "2025-04-16T20:07:06.981Z"
      },
      {
        "duration": 3384,
        "start_time": "2025-04-16T20:07:10.928Z"
      },
      {
        "duration": 2634,
        "start_time": "2025-04-16T20:07:14.314Z"
      },
      {
        "duration": 3233,
        "start_time": "2025-04-16T20:07:16.950Z"
      },
      {
        "duration": 4,
        "start_time": "2025-04-16T20:07:21.523Z"
      },
      {
        "duration": 15,
        "start_time": "2025-04-16T20:07:22.279Z"
      },
      {
        "duration": 1126,
        "start_time": "2025-04-16T20:07:24.193Z"
      },
      {
        "duration": 170,
        "start_time": "2025-04-16T20:07:27.323Z"
      },
      {
        "duration": 343,
        "start_time": "2025-04-16T20:07:28.598Z"
      },
      {
        "duration": 2,
        "start_time": "2025-04-16T20:07:28.943Z"
      },
      {
        "duration": 30,
        "start_time": "2025-04-16T20:07:28.982Z"
      },
      {
        "duration": 135,
        "start_time": "2025-04-16T20:07:29.974Z"
      },
      {
        "duration": 15,
        "start_time": "2025-04-16T20:07:30.273Z"
      },
      {
        "duration": 15,
        "start_time": "2025-04-16T20:07:30.425Z"
      },
      {
        "duration": 172,
        "start_time": "2025-04-16T20:07:30.924Z"
      },
      {
        "duration": 119,
        "start_time": "2025-04-16T20:07:31.757Z"
      },
      {
        "duration": 1209,
        "start_time": "2025-04-16T20:07:32.102Z"
      },
      {
        "duration": 493,
        "start_time": "2025-04-16T20:07:33.313Z"
      },
      {
        "duration": 173,
        "start_time": "2025-04-16T20:07:34.241Z"
      },
      {
        "duration": 30,
        "start_time": "2025-04-16T20:07:34.685Z"
      },
      {
        "duration": 138,
        "start_time": "2025-04-16T20:07:35.869Z"
      },
      {
        "duration": 10897,
        "start_time": "2025-04-16T20:07:36.199Z"
      },
      {
        "duration": 1619,
        "start_time": "2025-04-16T20:07:47.105Z"
      },
      {
        "duration": 362,
        "start_time": "2025-04-16T20:07:48.726Z"
      },
      {
        "duration": 42,
        "start_time": "2025-04-16T20:07:49.090Z"
      },
      {
        "duration": 32,
        "start_time": "2025-04-16T20:07:49.134Z"
      },
      {
        "duration": 29,
        "start_time": "2025-04-16T20:07:53.399Z"
      },
      {
        "duration": 27,
        "start_time": "2025-04-16T20:07:55.160Z"
      },
      {
        "duration": 6,
        "start_time": "2025-04-16T20:07:57.128Z"
      },
      {
        "duration": 165,
        "start_time": "2025-04-16T20:07:59.059Z"
      },
      {
        "duration": 28,
        "start_time": "2025-04-16T20:08:02.601Z"
      },
      {
        "duration": 1987,
        "start_time": "2025-04-16T20:08:16.912Z"
      },
      {
        "duration": 4,
        "start_time": "2025-04-16T20:08:18.905Z"
      },
      {
        "duration": 16,
        "start_time": "2025-04-16T20:08:21.456Z"
      },
      {
        "duration": 2051,
        "start_time": "2025-04-16T20:08:30.687Z"
      },
      {
        "duration": 7,
        "start_time": "2025-04-16T20:08:35.748Z"
      },
      {
        "duration": 11,
        "start_time": "2025-04-16T20:08:36.778Z"
      }
    ],
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": true,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}