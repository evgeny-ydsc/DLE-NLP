# Проект Автодополнение текстов

Вы работаете в соцсетевом приложении, где пользователи постят короткие тексты. В продукте стоит задача — добавить возможность автодополнения текстов. Разработчики просят вас создать модель, которую можно запускать на мобильных устройствах. Для смартфонов есть значительные требования по оперативной памяти и скорости работы, так что важна легковесность модели.

## Постановка задачи
**Создать нейросеть, которая на основе начала фразы предсказывает её продолжение**.

Поэтапное описание задачи:
1. Взять датасет от разработчиков, очистить его, подготовить для обучения модели.
1. Реализовать и обучить модель на основе рекуррентных нейронных сетей.
1. Замерить качество разработанной и обученной модели.
1. Взять более «тяжёлую» предобученную модель из Transformers и замерить её качество.
1. Проанализировать результаты и **дать рекомендации** разработчикам: стоит ли **использовать лёгкую модель или** лучше постараться поработать с ограничениями по памяти и **использовать большую предобученную**.

## Критерии успеха
- Используемые метрики качества: ROUGE-1 и ROUGE-2
- Минимальных порогов качества модели в задаче не задано


## Описание данных

датасет с короткими постами sentiment140

https://code.s3.yandex.net/deep-learning/tweets.txt

# Выводы
Была обучена модель на основе LSTM. Показатели на лучшем тексте из трёх: rouge1=0.121, rouge2=0.065

Также был использован предобученный трансформер, усреднённые показатели: rouge1=0.149, rouge2=0.019

Из этого следует, что использование предобученного трансформера предпочтительнее полученной LSTM-модели.
